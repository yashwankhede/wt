Q1.

<!DOCTYPE html>
<html>
<head>
<title>StudentRegistrationForm</title>
<script>
window.onload = function() {
    alert('HelloGoodMorning!');
};
</script>
</head>
<body>
<h1>Student Registration Form</h1>
<form>
<label for="name">Name:</label>
<input type="text" id="name" name="name" required><br><br>
<label for="email">Email:</label>
<input type="email" id="email" name="email" required><br><br>
<label for="phone">Phone:</label>
<input type="tel" id="phone" name="phone" required><br><br>
<label for="address">Address:</label>
<textarea id="address" name="address" required></textarea><br><br>
<input type="submit" value="Submit">
</form>
</body>
</html>


=============================
Q2.

import re
from nltk.tokenize import sent_tokenize

# Text paragraph
text = "So, keep working. Keep striving. Never give up. Fall down seven times, get up eight. Ease is a greater threat to progress than hardship. Ease is a greater threat to progress than hardship. So, keep moving, keep growing, keep learning. See you at work."

# Remove special characters and digits
text = re.sub('[^A-Za-z]+', '', text)

# Tokenize the sentences
sentences = sent_tokenize(text)

# Calculate the score of each sentence based on the number of words
# The sentences with more words will have a higher score
scores = {}
for sentence in sentences:
    words = sentence.split()
    score = len(words)
    scores[sentence] = score

# Sort the sentences based on their scores
sorted_sentences = sorted(scores.items(), key=lambda x: x[1], reverse=True)

# Extract the top 2 sentences with the highest scores as the summary
summary_sentences = [sentence[0] for sentence in sorted_sentences[:2]]
summary = "".join(summary_sentences)

# Print the summary
print(summary)
